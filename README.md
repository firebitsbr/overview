---


---

<h2 id="introduction">1. Introduction</h2>
<p>Welcome to 6.431x, an introduction to probabilistic models, including random processes and the basic elements of statistical inference.</p>
<p>The world is full of uncertainty: accidents, storms, unruly financial markets, noisy communications. The world is also full of data. Probabilistic modeling and the related field of statistical inference are the keys to analyzing data and making scientifically sound predictions.</p>
<p>The course covers all of the basic probability concepts, including:</p>
<ul>
<li>
<p>multiple discrete or continuous random variables, expectations, and conditional distributions</p>
</li>
<li>
<p>laws of large numbers</p>
</li>
<li>
<p>the main tools of Bayesian inference methods</p>
</li>
<li>
<p>an introduction to random processes (Poisson processes and Markov chains)</p>
</li>
</ul>
<h2 id="course-objectives">2. Course objectives</h2>
<p>Upon successful completion of this course, you will:</p>
<p><strong>At a conceptual level:</strong></p>
<ul>
<li>
<p>Master the basic concepts associated with  <strong>probability models</strong>  .</p>
</li>
<li>
<p>Be able to translate models described in words to mathematical ones.</p>
</li>
<li>
<p>Understand the main concepts and assumptions underlying  <strong>Bayesian and classical inference</strong>  .</p>
</li>
<li>
<p>Obtain some familiarity with the range of  <strong>applications of inference methods</strong>  .</p>
</li>
</ul>
<p><strong>At a more technical level:</strong></p>
<ul>
<li>
<p>Become familiar with basic and common  <strong>probability distributions</strong>  .</p>
</li>
<li>
<p>Learn how to use  <strong>conditioning</strong>  to simplify the analysis of complicated models.</p>
</li>
<li>
<p>Have facility manipulating  <strong>probability mass functions</strong>  ,  <strong>densities</strong>  , and  <strong>expectations</strong>  .</p>
</li>
<li>
<p>Develop a solid understanding of the concept of  <strong>conditional expectation</strong>  and its role in inference.</p>
</li>
<li>
<p>Understand the power of  <strong>laws of large numbers</strong>  and be able to use them when appropriate.</p>
</li>
<li>
<p>Become familiar with the basic inference methodologies (for both  <strong>estimation</strong>  and  <strong>hypothesis testing</strong>  ) and be able to apply them.</p>
</li>
<li>
<p>Acquire a good understanding of two  <strong>basic stochastic processes (Bernoulli and Poisson)</strong>  and their use in modeling.</p>
</li>
<li>
<p>Learn how to formulate simple dynamical models as  <strong>Markov chains</strong>  and analyze them.</p>
</li>
</ul>
<h2 id="study-guide">3. Study guide</h2>
<p><strong>A guide on how to use the wealth of available material</strong></p>
<p>This class provides you with a great wealth of material, perhaps more than you can fully digest. This “guide" offers some tips about how to use this material.</p>
<p><strong>Start with the overview of a unit,</strong>  when available. This will help you get an overview of what is to happen next. Similarly, at the end of a unit, watch the  <strong>unit summary</strong>  to consolidate your understanding of the “big picture" and of the relation between different concepts.</p>
<p><strong>Watch the lecture videos.</strong>  You may want to download the slides (clean or annotated) at the beginning of each lecture, especially if you cannot receive high-quality streaming video. Some of the lecture clips proceed at a moderate speed. Whenever you feel comfortable, you may want to speed up the video and run it faster, at 1.5x.</p>
<p><strong>Do the exercises!</strong>  The exercises that follow most of the lecture clips are a most critical part of this class. Some of the exercises are simple adaptations of you may have just heard. Other exercises will require more thought. Do your best to solve them right after each clip — do not defer this for later – so that you can consolidate your understanding. After your attempt, whether successful or not, do look at the solutions, which you will be able to see as soon as you submit your own answers.</p>
<p><strong>Solved problems and additional materials.</strong>  In most of the units, we are providing you with many problems that are solved by members of our staff. We provide both video clips and written solutions. Depending on your learning style, you may pick and choose which format to focus on. But in either case, it is important that you get exposed to a large number of problems.</p>
<p><strong>The textbook.</strong>  If you have access to the textbook, you can find more precise statements of what was discussed in lecture, additional facts, as well as several examples. While the textbook is recommended, the materials provided by this course are self-contained. See the “Textbook information" tab in Unit 0 for more details.</p>
<p><strong>Problem sets.</strong>  One can really master the subject only by solving problems – a large number of them. Some of the problems will be straightforward applications of what you have learned. A few of them will be more challenging. Do not despair if you cannot solve a problem – no one is expected to do everything perfectly. However, once the problem set solutions are released (which will happen on the due date of the problem set), make sure to go over the solutions to those problems that you could not solve correctly.</p>
<p><strong>Exams.</strong>  The midterm exams are designed so that in an on-campus version, learners would be given two hours. The final exam is designed so that in an on-campus version, learners would be given three hours. You should not expect to spend much more than this amount of time on them. In this respect, those weeks that have exams (and no problem sets!) will not have higher demands on your time. The level of difficulty of exam questions will be somewhere between the lecture exercises and homework problems.</p>
<p><strong>Time management.</strong>  The corresponding on-campus class is designed so that students with appropriate prerequisites spend about 12 hours each week on lectures, recitations, readings, and homework. You should expect a comparable effort, or more if you need to catch up on background material. In a typical week, there will be 2 hours of lecture clips, but it might take you 4-5 hours when you add the time spent on exercises. Plan to spend another 3-4 hours watching solved problems and additional materials, and on textbook readings. Finally, expect about 4 hours spent on the weekly problem sets.</p>
<p><strong>Additional practice problems.</strong>  For those of you who wish to dive even deeper into the subject, you can find a good collection of problems at the end of each chapter of the print edition of the book, whose solutions are available online.</p>
<h2 id="syllabus">4. Syllabus</h2>
<p><strong>6.431x Fall 2018 Syllabus</strong></p>
<p><strong>Unit 0: Overview</strong>  (released Tue. August 28)</p>
<p><strong>Unit 1: Probability models and axioms</strong>  (released Mon. Sep 3; Sections 1.1-1.2)<br>
L1: Probability models and axioms<br>
Problem Set 1 due on Tue Sept 11</p>
<p><strong>Unit 2: Conditioning and independence</strong>  (released Mon. Sept 10; Sections 1.3-1.5)<br>
L2: Conditioning and Bayes’ rule<br>
L3: Independence<br>
Problem Set 2 due on Tue Sept 18</p>
<p><strong>Unit 3: Counting</strong>  (released Mon. Sept 17; Section 1.6)<br>
L4: Counting<br>
Problem Set 3 due on Tue Sept 25</p>
<p><strong>Unit 4: Discrete random variables</strong>  (released Wed. Sept 19; Sections 2.1-2.7)<br>
L5: Probability mass functions and expectations<br>
L6: Variance; Conditioning on an event; Multiple r.v.'s<br>
L7: Conditioning on a random variable; Independence of r.v.'s<br>
Problem Set 4 due on Tue Oct 2</p>
<p><strong>Exam 1 (Timed) : Covers material from L1 to L7</strong>  (released Wed. Oct 3; due on Tue. Oct 9)</p>
<p><strong>Unit 5: Continuous random variables</strong>  (released Mon. Oct 1; Sections 3.1-3.5)<br>
L8: Probability density functions<br>
L9: Conditioning on an event; Multiple r.v.‘s<br>
L10: Conditioning on a random variable; Independence; Bayes’ rule<br>
Problem Set 5 due on Tue. Oct 16</p>
<p><strong>Unit 6: Further topics on random variables</strong>  (released Mon. Oct 15; Sections 4.1-4.3, 4.5)<br>
L11: Derived distributions<br>
L12: Sums of r.v.'s; Covariance and correlation<br>
L13: Conditional expectation and variance revisited; Sum of a random number of r.v.'s<br>
Problem Set 6 due on Tue. Oct 23</p>
<p><strong>Unit 7: Bayesian inference</strong>  (released Mon. Oct 22 Sections 3.6, 8.1-8.4)<br>
L14: Introduction to Bayesian inference<br>
L15: Linear models with normal noise<br>
L16: Least mean squares (LMS) estimation<br>
L17: Linear least mean squares (LLMS) estimation<br>
Problem Set 7a due on Tue. Oct 30<br>
Problem Set 7b due on Tue. Nov 6</p>
<p><strong>Exam 2 (Timed): Covers material from L8 to L17</strong>  (released Wed. Nov 7; due on Nov 13)</p>
<p><strong>Unit 8: Limit theorems and classical statistics</strong>  (released Mon. Nov 5; Sections 5.1-5.4, pp. 466-475)<br>
L18: Inequalities, convergence, and the Weak Law of Large Numbers<br>
L19: The Central Limit Theorem (CLT)<br>
L20: An introduction to classical statistics<br>
Problem Set 8 due on Tue. Nov 27</p>
<p><strong>Unit 9: Bernoulli and Poisson processes</strong>  (released Tue. Nov 14; Sections 6.1-6-2)<br>
L21: The Bernoulli process<br>
L22: The Poisson process<br>
L23: More on the Poisson process<br>
Problem Set 9 due on Tue. Dec 4</p>
<p><strong>Unit 10: Markov chains</strong>  (released Tue. Nov 26; Sections 7.1-7-4)<br>
L24: Finite-state Markov chains<br>
L25: Steady-state behavior of Markov chains<br>
L26: Absorption probabilities and expected time to absorption<br>
Problem Set 10 due on Tue. Dec 11</p>
<p><strong>Final Exam (Timed)</strong>  (released Wed. Dec 12; due on Sun. Dec 23)</p>
<p>*<strong>Note: Problem set and exam due dates are at the end of the specified date, at 23:59 UTC.</strong></p>
<h2 id="collaboration-guidelines">5. Collaboration guidelines</h2>
<p>We encourage you to interact with your fellow learners and engage in active discussion about the course. Please use the guidelines below for acceptable collaboration.</p>
<p>The staff will be proactive in removing posts and replies in the discussion forum that have stepped over the line.</p>
<ul>
<li>
<p>Given a problem, it is ok to discuss the general approach to solving the problem.</p>
</li>
<li>
<p>You can work jointly to come up with the general steps for the solution.</p>
</li>
<li>
<p>It is ok to get a hint, or several hints for that matter, if you get stuck while solving a problem.</p>
</li>
<li>
<p>You should work out the details of the solution yourself.</p>
</li>
<li>
<p>It is not ok to take someone else’s solution and simply copy the answers from their solution into your checkboxes.</p>
</li>
<li>
<p>It is not ok to take someone else’s formula and plug in your own numbers to get the final answer.</p>
</li>
<li>
<p>It is not ok to post answers to homework and lab problems before the submission deadline.</p>
</li>
<li>
<p>It is not ok to look at a full step-by-step solution to a problem before the submission deadline.</p>
</li>
<li>
<p>It is ok to have someone show you a few steps of a solution where you have been stuck for a while, provided of course, you have attempted to solve it yourself without success.</p>
</li>
<li>
<p>After you have collaborated with others in generating a correct solution, a good test to see if you were engaged in acceptable collaboration is to make sure that you are able to do the problem on your own.</p>
</li>
</ul>
<h2 id="textbook">6. Textbook</h2>
<p>The class follows closely the text Introduction to Probability, 2nd edition, by Bertsekas and Tsitsiklis, Athena Scientific, 2008; see the publisher’s website or <a href="http://Amazon.com">Amazon.com</a> for more information.</p>
<p>While this textbook is recommended, the materials provided by this course are self-contained. Furthermore, the publisher has made available, for the purposes of this class, the summary tables that are included in the text. These can be found under the “Resources" tab, or directly by following this  <a href="https://courses.edx.org/courses/course-v1:MITx+6.431x+3T2018/pdfbook/0/chapter/1/1">link</a>. In various places within the courseware, there will also be links to specific sections and pages to the excerpts from the textbook relevant to the material at hand. These links will also take you to the e-reader, jumping directly to the specific sections and pages.</p>
<p>To adjust the zoom level in the e-reader, click the ‘+’ and ‘-’ buttons at the top-right to zoom in and out, respectively. Or, choose a specific zoom level using the drop-down menu. Depending on your operating system and web browser, you may encounter occasional artifacts or imperfect rendering of some formulas. Please try adjusting the zoom level to find the one that gives the best readability. We recommend using Firefox as it renders the text most accurately.</p>

